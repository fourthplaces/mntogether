---
title: Emergency Resource Aggregator & AI-Powered Volunteer Matching Platform
type: feat
date: 2026-01-27
status: planned
priority: high
deepened: 2026-01-27
research_agents: 6
---

## ğŸ¯ Critical Simplification (2026-01-27 Evening)

**Philosophy Alignment**: This plan was overbuilt - it accidentally re-introduced "matching platform" patterns that conflict with our stated "relevance notifier" MVP.

### What Was Removed (OpenAI Feedback)

1. **âŒ Match lifecycle removed**: No `match` table, no `match_status`, no acceptMatch/declineMatch
   - **Why**: We notify, we don't coordinate. Implied bilateral acknowledgment violates philosophy.

2. **âŒ Similarity scores removed**: No `similarity_score`, no `confidence_score`
   - **Why**: Fake precision. Stored scores become promises. Keep ephemeral in code only.

3. **âŒ Service type enum removed**: Changed from rigid `ENUM('FOOD', 'SHELTER', ...)` to `TEXT`
   - **Why**: Text-first means don't freeze categories early. Anti-fragile storage.

4. **âŒ Complex volunteer/need schemas removed**: No rigid fields like "skills", "hours_available", "timeframe"
   - **Why**: Just store `searchable_text`. AI can extract structure later if needed.

5. **âŒ Organization side of match removed**: Orgs don't view volunteer state or "accept" matches
   - **Why**: We facilitate contact, not outcomes. No shared workflow.

### What Was Simplified

- **3 tables instead of 7**: `volunteers`, `organization_needs`, `notifications`
- **Text-first storage**: `searchable_text` is source of truth (evolvable, no migrations)
- **Simple throttling**: `notification_count_this_week` (max 3), no complex policies
- **Notification tracking**: Just `clicked`, `responded` (optional analytics)
- **Status as text**: "active", "filled", "expired" (not enforced ENUMs yet)

### Result

**Before**: Marketplace with match lifecycle, confidence scores, rigid taxonomy
**After**: Pure relevance notifier - we surface opportunities, humans decide elsewhere

---

## ğŸ”¬ Enhancement Summary

**Deepened on:** 2026-01-27
**Research agents deployed:** 6 (Framework Docs, Best Practices, Security, Performance, Data Integrity)
**Critical findings:** 23 security vulnerabilities, 7 performance bottlenecks, 8 data integrity issues

### Key Improvements Discovered

1. **Security Hardening Required**: 23 critical/high-severity vulnerabilities identified including rate limiting gaps, prompt injection risks, XSS vulnerabilities, and missing database access controls
2. **Performance Optimization**: 7 major bottlenecks found with specific fixes (composite indexes will provide 50-100x improvement on common queries)
3. **Data Integrity Fixes**: Missing cascade behaviors on foreign keys will cause orphaned records - must add before launch
4. **Cost Optimization**: Batch processing can reduce Claude API costs by 50%, prompt caching by 90%
5. **Modern API Patterns**: Updated to use latest Claude 4.5 models and structured outputs

---

# Emergency Resource Aggregator & AI-Powered Volunteer Matching Platform

## Overview

Build an **AI-powered volunteer matching platform** for Minnesota that connects organizations with people who can help during the current crisis.

### MVP Scope (Simplified, Focused)

**Core Flow**:
1. **Import Resources** (CSV â†’ JSON) - Generic importer for any Excel export
2. **AI Extracts Needs** - Scrape org websites â†’ identify needs ("need drivers", "need food donations")
3. **Volunteers Register** - Submit what they can offer via mobile app (push notification enabled)
4. **Vector Matching** - "Who can help with driving?" â†’ Query volunteer embeddings
5. **Push Notifications** - Volunteer gets match â†’ Taps â†’ Sees contact info â†’ Reaches out directly

**What's Included in MVP**:
- âœ… Generic CSV import (admin can import any CSV from Excel)
- âœ… AI-powered need extraction from org websites (rig.rs + OpenAI)
- âœ… Volunteer offer submissions (Expo app, anonymous)
- âœ… Vector similarity matching (pgvector + OpenAI embeddings)
- âœ… Push notifications (Expo notifications)
- âœ… Bullet list of needs + summaries (easy to scan)
- âœ… Direct contact info reveal on match
- âœ… Social sharing (React Native share)

**What's NOT in MVP**:
- âŒ Complex verification workflows (admins vet manually)
- âŒ Tracking "successful connections" (just facilitate contact)
- âŒ Organization accounts/login (just websites submitted)
- âŒ Public web directory (Expo app serves both mobile + web)

**Key Principle**: Simplicity. Import resources â†’ Extract needs â†’ Match volunteers â†’ Notify â†’ Facilitate contact.

## Problem Statement / Motivation

During the current crisis in Minnesota, people who want to help face a critical matching problem:

### The Challenge
- Organizations need specific help (drivers, food, translators) but can't reach the right people
- Volunteers want to help but don't know which organizations need their specific skills
- Information is scattered: spreadsheets, Facebook posts, email chains, word-of-mouth
- By the time a volunteer learns about a need, it's often too late or already filled

### Why This Matters
- **Urgency**: During a crisis, fast connections save lives
- **Inefficiency**: Organizations waste time broadcasting needs instead of serving
- **Missed Matches**: A bilingual lawyer exists but never hears the immigrant center needs them
- **Volunteer Burnout**: People get 100 generic "help needed" posts and tune out

### The Solution
Create an **AI-powered matching platform** that:
1. **Knows what orgs need** - Scrapes org websites, extracts structured needs
2. **Knows who can help** - Volunteers submit offers, creates searchable embeddings
3. **Matches automatically** - "Who can help drive?" â†’ Query vector DB â†’ Find drivers
4. **Notifies instantly** - Push notification to matched volunteer with contact info
5. **Facilitates contact** - Volunteer taps notification â†’ Sees org details â†’ Reaches out directly

**Result**: Right volunteer, right need, right time. No manual coordination.

## Proposed Solution

Build an **AI-powered matching system** in four stages:

### Stage 1: Generic CSV Importer

**Admin Import Flow**:
```
Admin â†’ Upload CSV â†’ Map columns â†’ Preview â†’ Import
```

**Features**:
- Accept any CSV file (exported from Excel, Google Sheets, etc.)
- Column mapper: "Which column is organization name? Which is website URL?"
- Preview parsed data before import
- Bulk import to `resource` table with `PENDING` status

**Example CSV formats supported**:
```csv
# Format 1: Simple list
Organization Name,Website,Phone,Email
Church of Hope,https://churchofhope.org,555-1234,info@church.org

# Format 2: With services
Name,URL,Services Offered,Contact
Food Bank MN,https://foodbank.org,"Food, Supplies",contact@foodbank.org

# Format 3: Complex (dad's format)
Church/Religious Organization,County,Address,URL,Facebook Page,Phone #,Immigrant Services Offered
International Friendship Center,Dakota,"1801 E Cliff Rd, Burnsville",https://ifc.org,,612-555-1234,"Free classes"
```

**Why Generic?**:
- Friends/family can contribute their own data sources
- No single standard format - handle anything
- Lowers barrier to contribution

---

### Stage 2: AI Need Extraction

**From Imported Resources â†’ Structured Needs**:

```rust
// For each imported resource
1. Scrape website using Firecrawl
2. Pass scraped content to rig.rs with OpenAI
3. Extract: "What does this org need?" (specific, actionable needs)
4. Create OrganizationNeed records with embeddings
```

**Example Extraction**:
```
Website content: "We desperately need Spanish-speaking volunteers to help with intake..."
AI extracts:
- Need: "Spanish-speaking intake volunteers"
- Urgency: HIGH
- Skills: ["Spanish", "intake", "volunteer coordination"]
- Embedding: [0.234, 0.892, ...] (1536-dim vector)
```

**Why This Matters**:
- Turns vague "help us" into specific, matchable needs
- Creates searchable vector embeddings
- Enables "who can help with X?" queries

---

### Stage 3: Volunteer Registration (Expo App)

**Volunteer Flow**:
```
1. Open app â†’ "I can help" button
2. Enter: "I'm a bilingual lawyer with immigration experience"
3. (Optional) Location, availability
4. Submit â†’ Embedding created â†’ Push token registered
```

**No login required** - Just:
- Email (for contact)
- Description of what they can offer
- Push notification token (Expo)

**Database**:
- `volunteer_offer` table
- Embedding generated immediately
- Status: ACTIVE

---

### Stage 4: AI Matching & Push Notifications

**Matching Query**:
```rust
// "Who can help with [need]?"
let need_embedding = openai.embed("Spanish-speaking intake volunteers").await?;

let matches = sqlx::query!(
    r#"
    SELECT id, description, email,
           1 - (embedding <=> $1) as similarity
    FROM volunteer_offer
    WHERE status = 'ACTIVE'
    AND 1 - (embedding <=> $1) > 0.7
    ORDER BY similarity DESC
    LIMIT 5
    "#,
    need_embedding
).fetch_all(pool).await?;

// Send push notifications to top 5 matches
for match in matches {
    expo.send_push({
        to: match.push_token,
        title: "Organization needs your help!",
        body: "Church of Hope needs Spanish-speaking intake volunteers",
        data: { need_id, org_id }
    });
}
```

**Volunteer Taps Notification**:
```
1. Opens app â†’ Shows need details
2. "View Contact Info" button
3. Reveals: Church of Hope, 555-1234, info@church.org
4. Volunteer reaches out directly
```

**Social Sharing**:
```typescript
// In Expo app
import { Share } from 'react-native';

const shareNeed = async () => {
  await Share.share({
    message: 'Church of Hope needs Spanish-speaking volunteers!',
    url: 'https://app.mndigitalaid.org/needs/abc123',
    title: 'Help Needed'
  });
};
```

## Technical Approach

### Platform Architecture: Two Apps

**ğŸ“± Expo App** (Mobile + Web):
- **Main public app** - volunteers and general users
- Cross-platform: iOS, Android, Web (same codebase)
- Push notifications (Expo notifications API)
- Anonymous usage (no login required)
- React Native StyleSheet for styling

**Screens**:
- Home: List of needs (bullet list + summaries)
- Offer: "I can help" form
- Notifications: Received matches
- Need Detail: Full info + contact reveal

**ğŸ–¥ï¸ Admin SPA** (React Web App):
- **Admin-only panel** - separate from public app
- Clerk authentication (admins only)
- CSV importer with column mapper
- Review queue for imported resources
- Need moderation
- Tailwind CSS for styling

**Deployed Separately**:
- Expo App: Expo EAS (mobile) + Vercel (web)
- Admin SPA: Vercel or Netlify
- Both connect to same Rust GraphQL API

### Why This Architecture?
- **Expo serves both mobile + web**: One codebase for public users
- **Push notifications**: Native mobile notifications for matches
- **Admin stays separate**: Clear boundary, simpler security
- **No app download required**: Web version of Expo app works in browser

---

### Tech Stack

**Backend API**: Rust with seesaw-rs event-driven architecture
- Framework: seesaw-rs event bus + Tokio async runtime
- Web server: Axum (from seesaw-rs ecosystem) or Actix-web
- GraphQL: Juniper for schema definition and execution
- Event-driven coordination for complex workflows
- One Command = One Effect = One Transaction pattern
- Reasoning: Type safety, performance, deterministic behavior, excellent async support

#### ğŸ” Architecture: seesaw-rs Event-Driven Pattern

**Core Concepts from seesaw-rs**:
- **Events** = Facts (what happened) - immutable, no IO
- **Commands** = Intent (requests for IO with transaction authority)
- **Machines** = Pure decision logic (state machines, no async, no IO)
- **Effects** = Stateless IO handlers (database, API calls, etc.)
- **One Command = One Transaction** - Clear authority boundaries

**Example: Resource Import Flow**:
```rust
// 1. Define events (facts)
#[derive(Debug, Clone, Serialize, Deserialize)]
enum ResourceEvent {
    XlsxUploaded { file_id: Uuid, row_count: usize },
    RowParsed { file_id: Uuid, row_index: usize, data: serde_json::Value },
    ResourceExtracted { file_id: Uuid, resource_id: Uuid, confidence: i32 },
    ExtractionFailed { file_id: Uuid, row_index: usize, error: String },
    ImportCompleted { file_id: Uuid, success_count: usize, failed_count: usize },
}

impl Event for ResourceEvent {}

// 2. Define commands (intent)
#[derive(Debug, Clone, Serialize, Deserialize)]
enum ResourceCommand {
    ExtractResourceFromRow { file_id: Uuid, row_index: usize, row_data: serde_json::Value },
    SavePendingResource { resource: PendingResource },
    MarkImportComplete { file_id: Uuid },
}

impl Command for ResourceCommand {}

// 3. Define machine (pure state transitions)
struct ImportMachine {
    pending_rows: HashMap<Uuid, HashSet<usize>>,
    completed_rows: HashMap<Uuid, usize>,
    failed_rows: HashMap<Uuid, Vec<usize>>,
}

impl Machine for ImportMachine {
    type Event = ResourceEvent;
    type Command = ResourceCommand;

    fn decide(&mut self, event: &ResourceEvent) -> Option<ResourceCommand> {
        match event {
            ResourceEvent::RowParsed { file_id, row_index, data } => {
                self.pending_rows.entry(*file_id).or_default().insert(*row_index);
                Some(ResourceCommand::ExtractResourceFromRow {
                    file_id: *file_id,
                    row_index: *row_index,
                    row_data: data.clone(),
                })
            }
            ResourceEvent::ResourceExtracted { file_id, resource_id, .. } => {
                self.pending_rows.get_mut(file_id)?.remove(&row_index);
                *self.completed_rows.entry(*file_id).or_default() += 1;

                // Check if import complete
                if self.pending_rows.get(file_id)?.is_empty() {
                    Some(ResourceCommand::MarkImportComplete { file_id: *file_id })
                } else {
                    None
                }
            }
            _ => None
        }
    }
}

// 4. Define effect (IO handler)
struct ClaudeExtractionEffect {
    anthropic_client: anthropic::Client,
}

#[async_trait]
impl Effect for ClaudeExtractionEffect {
    type Command = ResourceCommand;

    async fn execute(&self, cmd: Self::Command, ctx: &EffectContext) -> Result<()> {
        match cmd {
            ResourceCommand::ExtractResourceFromRow { file_id, row_index, row_data } => {
                match self.extract_resource_data(&row_data).await {
                    Ok(resource) => {
                        ctx.emit(ResourceEvent::ResourceExtracted {
                            file_id,
                            resource_id: resource.id,
                            confidence: resource.confidence_score,
                        }).await;
                    }
                    Err(e) => {
                        ctx.emit(ResourceEvent::ExtractionFailed {
                            file_id,
                            row_index,
                            error: e.to_string(),
                        }).await;
                    }
                }
            }
            _ => {}
        }
        Ok(())
    }
}
```

**Why seesaw-rs?**
- **Deterministic**: Pure state machines make testing easy
- **Transactional**: One command = one atomic operation
- **Auditable**: All events are facts, easy to replay and debug
- **Scalable**: Event-driven allows parallel processing
- **Maintainable**: Clear separation of concerns (decide vs execute)

**Database**: PostgreSQL with SQLx (compile-time checked SQL)
- Library: SQLx for Rust - compile-time verified queries
- Type-safe: Queries checked against database schema at compile time
- No ORM overhead: Direct SQL with zero-cost abstractions
- Connection pooling: Built-in with deadpool-postgres
- Migrations: sqlx-cli for version-controlled schema changes
- Hosted on Railway ($5/month) or Supabase (free tier available)

#### ğŸ” Research Insights: SQLx Patterns

**Compile-Time Query Verification**:
```rust
// SQLx verifies this query against your database at compile time
let resources = sqlx::query_as!(
    Resource,
    r#"
    SELECT id, organization_name, service_type, city, contact_phone, contact_email
    FROM resource
    WHERE status = 'APPROVED'
    ORDER BY published_at DESC
    LIMIT $1
    "#,
    limit
)
.fetch_all(&pool)
.await?;

// If column doesn't exist or types mismatch, compile fails
```

**Connection Pool Setup**:
```rust
use sqlx::postgres::PgPoolOptions;

#[derive(Clone)]
pub struct Database {
    pool: PgPool,
}

impl Database {
    pub async fn new(database_url: &str) -> Result<Self> {
        let pool = PgPoolOptions::new()
            .max_connections(20)
            .acquire_timeout(Duration::from_secs(3))
            .connect(database_url)
            .await?;

        Ok(Self { pool })
    }

    pub fn pool(&self) -> &PgPool {
        &self.pool
    }
}
```

**Type-Safe Result Mapping**:
```rust
#[derive(Debug, sqlx::FromRow, Serialize, Deserialize)]
pub struct Resource {
    pub id: Uuid,
    pub organization_name: String,
    pub service_type: ServiceType,
    pub city: Option<String>,
    pub contact_phone: Option<String>,
    pub contact_email: Option<String>,
    pub status: ResourceStatus,
    pub published_at: Option<DateTime<Utc>>,
}

// Custom type mapping for enums
#[derive(Debug, sqlx::Type, Serialize, Deserialize)]
#[sqlx(type_name = "service_type", rename_all = "UPPERCASE")]
pub enum ServiceType {
    Food,
    Shelter,
    Medical,
    Supplies,
    Transportation,
    Legal,
    Financial,
    Education,
    Other,
}
```

**Transaction Safety**:
```rust
pub async fn approve_resource(
    pool: &PgPool,
    resource_id: Uuid,
    reviewer_id: Uuid,
) -> Result<Resource> {
    let mut tx = pool.begin().await?;

    // Update resource status
    let resource = sqlx::query_as!(
        Resource,
        r#"
        UPDATE resource
        SET status = 'APPROVED',
            published_at = NOW(),
            reviewed_by_id = $2
        WHERE id = $1
        RETURNING *
        "#,
        resource_id,
        reviewer_id
    )
    .fetch_one(&mut *tx)
    .await?;

    // Create audit log
    sqlx::query!(
        r#"
        INSERT INTO audit_log (id, resource_id, user_id, action, created_at)
        VALUES ($1, $2, $3, 'approved', NOW())
        "#,
        Uuid::new_v4(),
        resource_id,
        reviewer_id
    )
    .execute(&mut *tx)
    .await?;

    tx.commit().await?;
    Ok(resource)
}
```

**pgvector Support**:
```rust
use pgvector::Vector;

#[derive(Debug, sqlx::FromRow)]
pub struct VolunteerOffer {
    pub id: Uuid,
    pub description: String,
    pub embedding: Option<Vector>, // pgvector type
}

// Vector similarity search
pub async fn find_similar_offers(
    pool: &PgPool,
    need_embedding: &Vector,
    limit: i64,
) -> Result<Vec<(Uuid, f32)>> {
    let results = sqlx::query!(
        r#"
        SELECT id, 1 - (embedding <=> $1) as similarity
        FROM volunteer_offer
        WHERE status = 'ACTIVE'
        ORDER BY embedding <=> $1
        LIMIT $2
        "#,
        need_embedding as _,
        limit
    )
    .fetch_all(pool)
    .await?;

    Ok(results.into_iter()
        .map(|r| (r.id, r.similarity.unwrap_or(0.0)))
        .collect())
}
```

**Web Scraping**: Firecrawl
- Service: Hosted Firecrawl API or self-hosted
- Converts websites to clean markdown
- Handles JavaScript-heavy sites
- Pricing: Hobby tier $20/month (3,000 scrapes) or self-hosted (free)

#### ğŸ” Research Insights: Firecrawl + AI Extraction

**Firecrawl with Retry and Stealth Mode**:
```typescript
import FirecrawlApp from '@mendable/firecrawl-js'

const firecrawl = new FirecrawlApp({ apiKey: process.env.FIRECRAWL_API_KEY })

async function scrapeWithRetry(url: string, maxRetries = 3): Promise<string> {
  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      const result = await firecrawl.scrapeUrl(url, {
        formats: ['markdown'],
        onlyMainContent: true
      })

      // Check if blocked by status code
      const statusCode = result.metadata?.statusCode
      if ([401, 403, 500].includes(statusCode)) {
        console.log(`Blocked with ${statusCode}, trying stealth mode...`)
        return await firecrawl.scrapeUrl(url, {
          formats: ['markdown'],
          onlyMainContent: true,
          proxy: 'stealth' // Bypass anti-scraping measures
        })
      }

      return result.markdown || ''
    } catch (error) {
      if (attempt === maxRetries - 1) throw error
      await new Promise(r => setTimeout(r, Math.pow(2, attempt) * 1000))
    }
  }
  throw new Error('Scraping failed after retries')
}
```

**robots.txt Compliance** - Respect crawl delays:
```typescript
import robotsParser from 'robots-parser'

async function canScrape(url: string): Promise<{ allowed: boolean; delay: number }> {
  const robotsUrl = new URL('/robots.txt', url).href
  const response = await fetch(robotsUrl)
  const robots = robotsParser(robotsUrl, await response.text())

  return {
    allowed: robots.isAllowed(url, 'FirecrawlBot'),
    delay: robots.getCrawlDelay('FirecrawlBot') || 1000
  }
}
```

**Duplicate Detection Algorithm**:
```rust
// 3-stage duplicate detection: exact â†’ fuzzy â†’ semantic

use strsim::levenshtein;

pub async fn detect_duplicates(
    pool: &PgPool,
    org_name: &str,
    city: Option<&str>,
) -> Result<Vec<Uuid>> {
    // Stage 1: Exact match (case-insensitive)
    let normalized = org_name.to_lowercase().trim().to_string();

    let exact_match = sqlx::query!(
        r#"
        SELECT id FROM resource
        WHERE LOWER(TRIM(organization_name)) = $1
        AND ($2::TEXT IS NULL OR city = $2)
        LIMIT 1
        "#,
        normalized,
        city
    )
    .fetch_optional(pool)
    .await?;

    if let Some(m) = exact_match {
        return Ok(vec![m.id]);
    }

    // Stage 2: Fuzzy match (Levenshtein distance <= 3)
    let all_orgs = sqlx::query!(
        r#"
        SELECT id, organization_name
        FROM resource
        WHERE $1::TEXT IS NULL OR city = $1
        "#,
        city
    )
    .fetch_all(pool)
    .await?;

    let fuzzy_matches: Vec<Uuid> = all_orgs
        .into_iter()
        .filter(|org| {
            let distance = levenshtein(
                &normalized,
                &org.organization_name.to_lowercase()
            );
            distance <= 3
        })
        .map(|org| org.id)
        .collect();

    if !fuzzy_matches.is_empty() {
        return Ok(fuzzy_matches);
    }

    // Stage 3: Semantic match (vector similarity > 0.9)
    // Only if embeddings are enabled
    if std::env::var("ENABLE_VECTOR_DEDUPLICATION").is_ok() {
        let embedding = generate_embedding(org_name).await?;

        let semantic_matches = sqlx::query!(
            r#"
            SELECT id
            FROM resource
            WHERE ($1::TEXT IS NULL OR city = $1)
            AND name_embedding IS NOT NULL
            AND 1 - (name_embedding <=> $2) > 0.9
            LIMIT 5
            "#,
            city,
            embedding as _
        )
        .fetch_all(pool)
        .await?;

        return Ok(semantic_matches.into_iter().map(|m| m.id).collect());
    }

    Ok(vec![])
}
```

**AI Extraction**: rig.rs with OpenAI
- Library: rig.rs - High-level Rust library for LLM applications
- Model: `gpt-4o` for extraction, `text-embedding-3-small` for embeddings
- Usage: Extract structured needs from scraped content, create embeddings
- Estimated cost: ~$20-30/month for MVP (parsing 50-100 pages/day + embeddings)

#### ğŸ” Research Insights: rig.rs with OpenAI

**Why rig.rs?**:
- High-level, ergonomic API for LLM operations
- Built-in support for structured outputs (JSON mode)
- Async/await with Tokio
- Built-in embeddings support
- Better than raw OpenAI API client

**Structured Extraction with rig.rs**:
```rust
use rig::{completion::Prompt, providers::openai};
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct ExtractedNeed {
    pub title: String,
    pub description: String,
    pub skills_needed: Vec<String>,
    pub urgency: String, // "high", "medium", "low"
    pub location: Option<String>,
}

pub struct NeedExtractor {
    client: openai::Client,
}

impl NeedExtractor {
    pub fn new(api_key: String) -> Self {
        let client = openai::Client::new(&api_key);
        Self { client }
    }

    pub async fn extract_needs(
        &self,
        scraped_content: &str,
        org_name: &str,
    ) -> Result<Vec<ExtractedNeed>> {
        let prompt = format!(
            r#"Analyze this content from {} and extract specific needs.

For each need, extract:
- title: Short description (e.g., "Spanish-speaking intake volunteers")
- description: What they need and why
- skills_needed: List of required skills/capabilities
- urgency: high, medium, or low
- location: City or area if mentioned

Content:
{}

Return JSON array of needs. Be specific and actionable.
"#,
            org_name, scraped_content
        );

        let response = self.client
            .agent("gpt-4o")
            .preamble("You extract volunteer needs from organization websites.")
            .temperature(0.3) // Lower = more consistent
            .build()
            .prompt(&prompt)
            .await?;

        let needs: Vec<ExtractedNeed> = serde_json::from_str(&response)?;
        Ok(needs)
    }

    pub async fn generate_embedding(&self, text: &str) -> Result<Vec<f32>> {
        let embedding = self.client
            .embeddings("text-embedding-3-small")
            .embed_query(text)
            .await?;

        Ok(embedding)
    }
}
```

**Usage in Effect Handler**:
```rust
use rig::providers::openai;

pub struct NeedExtractionEffect {
    extractor: NeedExtractor,
}

#[async_trait]
impl Effect for NeedExtractionEffect {
    type Command = ResourceCommand;

    async fn execute(&self, cmd: Self::Command, ctx: &EffectContext) -> Result<()> {
        match cmd {
            ResourceCommand::ExtractNeeds { resource_id, scraped_content, org_name } => {
                // Extract needs with rig.rs
                let needs = self.extractor
                    .extract_needs(&scraped_content, &org_name)
                    .await?;

                for need in needs {
                    // Generate embedding
                    let embedding_text = format!("{} {}", need.title, need.description);
                    let embedding = self.extractor
                        .generate_embedding(&embedding_text)
                        .await?;

                    // Emit event
                    ctx.emit(ResourceEvent::NeedExtracted {
                        resource_id,
                        need: need.clone(),
                        embedding,
                    }).await;
                }
            }
            _ => {}
        }
        Ok(())
    }
}
```

**Rate Limiting (Built-in with rig.rs)**:
```rust
// rig.rs handles rate limiting internally via reqwest middleware
use rig::providers::openai::Client;

pub fn create_rate_limited_client(api_key: String) -> Client {
    Client::new(&api_key)
        .with_rate_limit(50, std::time::Duration::from_secs(60)) // 50 req/min
}
```

**GraphQL API**: Juniper
- Schema definition library for Rust
- Type-safe GraphQL with compile-time validation
- Supports queries, mutations, subscriptions
- Integrates with Axum/Actix-web via juniper_axum/juniper_actix
- Async resolvers with Tokio

#### ğŸ” GraphQL API with Juniper

**Schema Definition**:
```rust
use juniper::{FieldResult, GraphQLObject, GraphQLEnum, GraphQLInputObject};

#[derive(GraphQLEnum, Clone, Copy)]
pub enum ServiceType {
    Food,
    Shelter,
    Medical,
    Supplies,
    Transportation,
    Legal,
    Financial,
    Education,
    Other,
}

#[derive(GraphQLObject)]
#[graphql(description = "An emergency resource organization")]
pub struct Resource {
    pub id: String,
    pub organization_name: String,
    pub service_type: ServiceType,
    pub city: Option<String>,
    pub contact_phone: Option<String>,
    pub contact_email: Option<String>,
    pub description: Option<String>,
    pub website: Option<String>,
}

pub struct Query {
    db: Database,
}

#[juniper::graphql_object]
impl Query {
    async fn resources(
        &self,
        status: Option<String>,
        limit: Option<i32>,
        cursor: Option<String>,
    ) -> FieldResult<Vec<Resource>> {
        let resources = sqlx::query_as!(
            Resource,
            r#"
            SELECT id, organization_name, service_type, city,
                   contact_phone, contact_email, description, website
            FROM resource
            WHERE status = COALESCE($1, 'APPROVED')
            AND ($2::UUID IS NULL OR id > $2::UUID)
            ORDER BY published_at DESC
            LIMIT $3
            "#,
            status,
            cursor.map(|c| Uuid::parse_str(&c).ok()).flatten(),
            limit.unwrap_or(50)
        )
        .fetch_all(self.db.pool())
        .await?;

        Ok(resources)
    }

    async fn resource(&self, id: String) -> FieldResult<Option<Resource>> {
        let resource = sqlx::query_as!(
            Resource,
            r#"
            SELECT id, organization_name, service_type, city,
                   contact_phone, contact_email, description, website
            FROM resource
            WHERE id = $1
            "#,
            Uuid::parse_str(&id)?
        )
        .fetch_optional(self.db.pool())
        .await?;

        Ok(resource)
    }
}

pub struct Mutation {
    db: Database,
    event_bus: Arc<EventBus>,
}

#[derive(GraphQLInputObject)]
pub struct CreateResourceInput {
    pub organization_name: String,
    pub service_type: ServiceType,
    pub contact_email: Option<String>,
    pub contact_phone: Option<String>,
    pub description: Option<String>,
}

#[juniper::graphql_object]
impl Mutation {
    async fn create_resource_submission(
        &self,
        input: CreateResourceInput,
    ) -> FieldResult<String> {
        // Emit event to seesaw-rs event bus
        self.event_bus.emit(ResourceEvent::SubmissionReceived {
            organization_name: input.organization_name,
            service_type: input.service_type,
            contact: ContactInfo {
                email: input.contact_email,
                phone: input.contact_phone,
            },
        }).await;

        Ok("Submission received".to_string())
    }

    async fn approve_resource(
        &self,
        context: &Context,
        resource_id: String,
    ) -> FieldResult<Resource> {
        // Check admin authorization
        let user_id = context.user_id.ok_or("Unauthorized")?;

        // Emit approval event
        self.event_bus.emit(ResourceEvent::ApprovalRequested {
            resource_id: Uuid::parse_str(&resource_id)?,
            reviewer_id: user_id,
        }).await;

        // Fetch and return resource
        let resource = self.fetch_resource(&resource_id).await?;
        Ok(resource)
    }
}

pub type Schema = juniper::RootNode<'static, Query, Mutation, juniper::EmptySubscription>;

pub fn create_schema(db: Database, event_bus: Arc<EventBus>) -> Schema {
    Schema::new(
        Query { db: db.clone() },
        Mutation { db, event_bus },
        juniper::EmptySubscription::new(),
    )
}
```

**Axum Integration**:
```rust
use axum::{
    extract::Extension,
    response::IntoResponse,
    routing::{get, post},
    Json, Router,
};
use juniper::http::{GraphQLRequest, graphiql};

async fn graphql_handler(
    Extension(schema): Extension<Arc<Schema>>,
    Extension(context): Extension<Context>,
    Json(request): Json<GraphQLRequest>,
) -> impl IntoResponse {
    let response = request.execute(&schema, &context).await;
    Json(response)
}

async fn graphiql_handler() -> impl IntoResponse {
    graphiql::graphiql_source("/graphql", None)
}

pub fn graphql_router(schema: Arc<Schema>) -> Router {
    Router::new()
        .route("/graphql", post(graphql_handler))
        .route("/graphiql", get(graphiql_handler))
        .layer(Extension(schema))
}
```

**Scheduling**: Tokio cron jobs
- Run scraping jobs every 4-6 hours using tokio-cron-scheduler
- In-process scheduler (no external dependencies)
- Alternative: systemd timers or Kubernetes CronJobs

**Email**: Resend
- Confirmation emails for org submissions
- Error notifications to admin
- Pricing: 3,000 emails/month free, then $20/month
- Estimated cost: $0/month (within free tier)

**Frontend #1: Expo App** (Public - Mobile + Web)
- Framework: React Native with Expo SDK 50+
- Runs on: iOS, Android, and Web (same codebase)
- GraphQL Client: Apollo Client
- Styling: React Native StyleSheet (not Tailwind)
- Push Notifications: Expo Notifications API
- Routing: Expo Router (file-based)
- No authentication required (anonymous usage)

**Frontend #2: Admin SPA** (React Web App)
- Framework: React 18+ with TypeScript
- GraphQL Client: Apollo Client for data fetching and caching
- State Management: Apollo Cache (no Redux needed)
- Routing: React Router v6
- Styling: Tailwind CSS
- UI Components: Shadcn UI
- Build Tool: Vite for fast development
- Authentication: Clerk (admins only)
- Deployed separately: Vercel, Netlify, or Cloudflare Pages

**Authentication**: Clerk
- Magic link authentication (passwordless)
- JWT tokens for GraphQL API authorization
- Admin role management
- Free tier: 10,000 MAU

**Styling**: Tailwind CSS
- Mobile-first responsive design
- High contrast for accessibility
- Fast development
- Shadcn UI components for polished UI

#### ğŸ” React Admin SPA with Apollo Client

**Apollo Client Setup**:
```typescript
// src/apollo-client.ts
import { ApolloClient, InMemoryCache, createHttpLink } from '@apollo/client'
import { setContext } from '@apollo/client/link/context'

const httpLink = createHttpLink({
  uri: import.meta.env.VITE_GRAPHQL_URL || 'http://localhost:8080/graphql',
})

const authLink = setContext((_, { headers }) => {
  const token = localStorage.getItem('auth_token')
  return {
    headers: {
      ...headers,
      authorization: token ? `Bearer ${token}` : '',
    }
  }
})

export const client = new ApolloClient({
  link: authLink.concat(httpLink),
  cache: new InMemoryCache(),
  defaultOptions: {
    watchQuery: {
      fetchPolicy: 'cache-and-network',
    },
  },
})
```

**GraphQL Queries with Codegen**:
```typescript
// src/graphql/queries.ts
import { gql } from '@apollo/client'

export const GET_RESOURCES = gql`
  query GetResources($status: String, $limit: Int, $cursor: String) {
    resources(status: $status, limit: $limit, cursor: $cursor) {
      id
      organizationName
      serviceType
      city
      contactPhone
      contactEmail
      description
    }
  }
`

export const APPROVE_RESOURCE = gql`
  mutation ApproveResource($resourceId: String!) {
    approveResource(resourceId: $resourceId) {
      id
      status
      publishedAt
    }
  }
`
```

**Type-Safe Hooks with GraphQL Code Generator**:
```bash
# Install codegen
npm install -D @graphql-codegen/cli @graphql-codegen/typescript @graphql-codegen/typescript-operations @graphql-codegen/typescript-react-apollo

# codegen.yml
schema: http://localhost:8080/graphql
documents: 'src/**/*.ts'
generates:
  src/generated/graphql.ts:
    plugins:
      - typescript
      - typescript-operations
      - typescript-react-apollo
```

```typescript
// Auto-generated hooks from GraphQL schema
import { useGetResourcesQuery, useApproveResourceMutation } from '@/generated/graphql'

function ReviewQueue() {
  const { data, loading, error } = useGetResourcesQuery({
    variables: { status: 'PENDING', limit: 20 }
  })

  const [approveResource] = useApproveResourceMutation({
    refetchQueries: ['GetResources'] // Auto-refresh list
  })

  if (loading) return <Skeleton />
  if (error) return <Error message={error.message} />

  return (
    <div>
      {data.resources.map(resource => (
        <ResourceCard
          key={resource.id}
          resource={resource}
          onApprove={() => approveResource({ variables: { resourceId: resource.id } })}
        />
      ))}
    </div>
  )
}
```

**Optimistic Updates**:
```typescript
const [approveResource] = useApproveResourceMutation({
  optimisticResponse: {
    approveResource: {
      __typename: 'Resource',
      id: resourceId,
      status: 'APPROVED',
      publishedAt: new Date().toISOString(),
    }
  },
  update: (cache, { data }) => {
    // Remove from pending queue
    cache.modify({
      fields: {
        resources(existingRefs, { readField }) {
          return existingRefs.filter(
            ref => readField('id', ref) !== resourceId
          )
        }
      }
    })
  }
})
```

#### ğŸ” Expo App Architecture

**Project Structure**:
```
mndigitalaid-app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (tabs)/
â”‚   â”‚   â”œâ”€â”€ index.tsx           # Home: List of needs
â”‚   â”‚   â”œâ”€â”€ offer.tsx           # "I can help" form
â”‚   â”‚   â””â”€â”€ notifications.tsx   # Match history
â”‚   â”œâ”€â”€ need/[id].tsx           # Need detail + contact reveal
â”‚   â””â”€â”€ _layout.tsx             # Root layout with Apollo
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ NeedCard.tsx            # Bullet item in list
â”‚   â”œâ”€â”€ OfferForm.tsx           # Volunteer submission
â”‚   â””â”€â”€ ContactReveal.tsx       # Show org contact info
â”œâ”€â”€ graphql/
â”‚   â”œâ”€â”€ queries.ts              # GraphQL queries
â”‚   â””â”€â”€ mutations.ts            # GraphQL mutations
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ apollo.ts               # Apollo Client setup
â”‚   â””â”€â”€ notifications.ts        # Expo push notifications
â””â”€â”€ app.json
```

**Push Notification Setup**:
```typescript
// lib/notifications.ts
import * as Notifications from 'expo-notifications';
import * as Device from 'expo-device';
import Constants from 'expo-constants';

export async function registerForPushNotifications(): Promise<string | null> {
  if (!Device.isDevice) {
    alert('Push notifications only work on physical devices');
    return null;
  }

  const { status: existingStatus } = await Notifications.getPermissionsAsync();
  let finalStatus = existingStatus;

  if (existingStatus !== 'granted') {
    const { status } = await Notifications.requestPermissionsAsync();
    finalStatus = status;
  }

  if (finalStatus !== 'granted') {
    alert('Failed to get push token');
    return null;
  }

  const token = (await Notifications.getExpoPushTokenAsync({
    projectId: Constants.expoConfig?.extra?.eas?.projectId,
  })).data;

  return token;
}

// Handle notification received while app is foregrounded
Notifications.setNotificationHandler({
  handleNotification: async () => ({
    shouldShowAlert: true,
    shouldPlaySound: true,
    shouldSetBadge: false,
  }),
});
```

**Home Screen (Need List)**:
```typescript
// app/(tabs)/index.tsx
import { useQuery } from '@apollo/client';
import { FlatList, StyleSheet, Text, View } from 'react-native';
import { GET_NEEDS } from '@/graphql/queries';
import NeedCard from '@/components/NeedCard';

export default function HomeScreen() {
  const { data, loading, error } = useQuery(GET_NEEDS, {
    variables: { status: 'ACTIVE', limit: 50 }
  });

  if (loading) return <Text>Loading needs...</Text>;
  if (error) return <Text>Error: {error.message}</Text>;

  return (
    <View style={styles.container}>
      <Text style={styles.header}>Organizations Need Help</Text>
      <FlatList
        data={data.organizationNeeds.nodes}
        keyExtractor={(item) => item.id}
        renderItem={({ item }) => <NeedCard need={item} />}
      />
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    padding: 16,
    backgroundColor: '#fff',
  },
  header: {
    fontSize: 24,
    fontWeight: 'bold',
    marginBottom: 16,
  },
});
```

**Need Card Component (Bullet List Item)**:
```typescript
// components/NeedCard.tsx
import { StyleSheet, Text, TouchableOpacity, View } from 'react-native';
import { router } from 'expo-router';
import { Share } from 'react-native';

export default function NeedCard({ need }) {
  const handleShare = async () => {
    await Share.share({
      message: `${need.organizationName} needs: ${need.title}`,
      url: `https://app.mndigitalaid.org/need/${need.id}`,
      title: 'Help Needed'
    });
  };

  return (
    <TouchableOpacity
      style={styles.card}
      onPress={() => router.push(`/need/${need.id}`)}
    >
      <Text style={styles.urgency}>
        {need.urgency === 'HIGH' ? 'ğŸ”´' : need.urgency === 'MEDIUM' ? 'ğŸŸ¡' : 'ğŸŸ¢'}
      </Text>
      <View style={styles.content}>
        <Text style={styles.title}>{need.title}</Text>
        <Text style={styles.org}>{need.organizationName}</Text>
        <Text style={styles.summary} numberOfLines={2}>
          {need.description}
        </Text>
        {need.location && (
          <Text style={styles.location}>ğŸ“ {need.location}</Text>
        )}
      </View>
      <TouchableOpacity onPress={handleShare}>
        <Text style={styles.share}>â†—ï¸</Text>
      </TouchableOpacity>
    </TouchableOpacity>
  );
}

const styles = StyleSheet.create({
  card: {
    flexDirection: 'row',
    backgroundColor: '#f9f9f9',
    padding: 16,
    marginBottom: 12,
    borderRadius: 8,
    borderLeftWidth: 4,
    borderLeftColor: '#3b82f6',
  },
  urgency: {
    fontSize: 20,
    marginRight: 12,
  },
  content: {
    flex: 1,
  },
  title: {
    fontSize: 16,
    fontWeight: '600',
    marginBottom: 4,
  },
  org: {
    fontSize: 14,
    color: '#666',
    marginBottom: 4,
  },
  summary: {
    fontSize: 14,
    color: '#333',
    marginBottom: 4,
  },
  location: {
    fontSize: 12,
    color: '#888',
  },
  share: {
    fontSize: 24,
  },
});
```

**Offer Form (Volunteer Registration)**:
```typescript
// app/(tabs)/offer.tsx
import { useState, useEffect } from 'react';
import { StyleSheet, Text, TextInput, Button, View } from 'react-native';
import { useMutation } from '@apollo/client';
import { CREATE_VOLUNTEER_OFFER } from '@/graphql/mutations';
import { registerForPushNotifications } from '@/lib/notifications';

export default function OfferScreen() {
  const [email, setEmail] = useState('');
  const [description, setDescription] = useState('');
  const [pushToken, setPushToken] = useState<string | null>(null);

  const [createOffer, { loading }] = useCreateVolunteerOfferMutation();

  useEffect(() => {
    registerForPushNotifications().then(setPushToken);
  }, []);

  const handleSubmit = async () => {
    if (!email || !description) {
      alert('Please fill in all fields');
      return;
    }

    await createOffer({
      variables: {
        input: {
          email,
          title: description.substring(0, 100),
          description,
          notifyEmail: true,
          pushToken,
        }
      }
    });

    alert('Thanks! We\'ll notify you when there\'s a match.');
    setEmail('');
    setDescription('');
  };

  return (
    <View style={styles.container}>
      <Text style={styles.header}>I Can Help</Text>
      <Text style={styles.label}>Email (for notifications)</Text>
      <TextInput
        style={styles.input}
        value={email}
        onChangeText={setEmail}
        placeholder="your@email.com"
        keyboardType="email-address"
        autoCapitalize="none"
      />
      <Text style={styles.label}>What can you help with?</Text>
      <TextInput
        style={[styles.input, styles.textArea]}
        value={description}
        onChangeText={setDescription}
        placeholder="I'm a bilingual lawyer with immigration experience..."
        multiline
        numberOfLines={6}
      />
      <Button
        title={loading ? 'Submitting...' : 'Submit Offer'}
        onPress={handleSubmit}
        disabled={loading}
      />
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    padding: 16,
    backgroundColor: '#fff',
  },
  header: {
    fontSize: 24,
    fontWeight: 'bold',
    marginBottom: 24,
  },
  label: {
    fontSize: 14,
    fontWeight: '600',
    marginBottom: 8,
    color: '#333',
  },
  input: {
    borderWidth: 1,
    borderColor: '#ddd',
    borderRadius: 8,
    padding: 12,
    marginBottom: 16,
    fontSize: 16,
  },
  textArea: {
    height: 120,
    textAlignVertical: 'top',
  },
});
```

### Architecture Diagram

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                         SYSTEM ARCHITECTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND LAYER                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  ADMIN PANEL     â”‚      â”‚  PUBLIC WEB      â”‚                   â”‚
â”‚  â”‚  (React SPA)     â”‚      â”‚  (React SPA)     â”‚                   â”‚
â”‚  â”‚  - Apollo Client â”‚      â”‚  - Apollo Client â”‚                   â”‚
â”‚  â”‚  - GraphQL       â”‚      â”‚  - GraphQL       â”‚                   â”‚
â”‚  â”‚  - Clerk Auth    â”‚      â”‚  - No Auth       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚           â”‚                          â”‚                             â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                      â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚         MOBILE APP (v2.0 - Future)          â”‚                 â”‚
â”‚  â”‚         React Native + Expo                  â”‚                 â”‚
â”‚  â”‚         - Push Notifications                 â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                     â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ GraphQL over HTTP
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         API LAYER (RUST)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    GraphQL API (Juniper)                 â”‚    â”‚
â”‚  â”‚  - Query: resources, needs, offers, matches             â”‚    â”‚
â”‚  â”‚  - Mutation: create, approve, reject, merge             â”‚    â”‚
â”‚  â”‚  - Subscriptions: real-time updates (optional)          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚                                                   â”‚
â”‚               â–¼                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              seesaw-rs Event Bus                         â”‚    â”‚
â”‚  â”‚  - Events: facts (ResourceExtracted, Approved, etc.)    â”‚    â”‚
â”‚  â”‚  - Commands: intent (ExtractResource, SaveResource)     â”‚    â”‚
â”‚  â”‚  - Runtime: orchestrates event flow                     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚                                                   â”‚
â”‚               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚               â–¼           â–¼           â–¼             â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Import      â”‚  â”‚ Approval â”‚  â”‚ Matchingâ”‚  â”‚ Scraping   â”‚    â”‚
â”‚  â”‚  Machine     â”‚  â”‚ Machine  â”‚  â”‚ Machine â”‚  â”‚ Machine    â”‚    â”‚
â”‚  â”‚              â”‚  â”‚          â”‚  â”‚         â”‚  â”‚            â”‚    â”‚
â”‚  â”‚  Pure State  â”‚  â”‚ Decides  â”‚  â”‚ Finds   â”‚  â”‚ Schedules  â”‚    â”‚
â”‚  â”‚  Transitions â”‚  â”‚ Auto/    â”‚  â”‚ Similar â”‚  â”‚ Jobs       â”‚    â”‚
â”‚  â”‚              â”‚  â”‚ Manual   â”‚  â”‚ Vectors â”‚  â”‚            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚               â”‚              â”‚             â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                         â”‚                                         â”‚
â”‚                         â–¼ Commands                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                   Effect Handlers                        â”‚    â”‚
â”‚  â”‚  - ClaudeExtractionEffect (AI)                          â”‚    â”‚
â”‚  â”‚  - DatabaseEffect (SQLx transactions)                   â”‚    â”‚
â”‚  â”‚  - EmbeddingEffect (OpenAI API)                         â”‚    â”‚
â”‚  â”‚  - NotificationEffect (Email/SMS)                       â”‚    â”‚
â”‚  â”‚  - ScrapingEffect (Firecrawl)                           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â”‚ SQLx queries, external APIs
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PERSISTENCE LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              PostgreSQL with pgvector                    â”‚    â”‚
â”‚  â”‚  - Tables: resource, user, audit_log, etc.              â”‚    â”‚
â”‚  â”‚  - Vector indexes (HNSW) for semantic search            â”‚    â”‚
â”‚  â”‚  - Row-Level Security (RLS) for multi-tenancy           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      EXTERNAL SERVICES                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  â€¢ Claude API (Anthropic) - AI extraction                        â”‚
â”‚  â€¢ OpenAI API - Text embeddings for matching                     â”‚
â”‚  â€¢ Firecrawl - Web scraping (v2.0)                               â”‚
â”‚  â€¢ Clerk - Authentication and user management                    â”‚
â”‚  â€¢ Resend - Email notifications (v2.0)                           â”‚
â”‚  â€¢ Twilio - SMS notifications (v2.0)                             â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

KEY FLOW: Resource Import
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. Admin uploads XLSX via GraphQL mutation
2. GraphQL resolver emits XlsxUploaded event to seesaw-rs bus
3. ImportMachine decides: emit ExtractResource command for each row
4. ClaudeExtractionEffect executes: calls Claude API, extracts data
5. Effect emits ResourceExtracted event with result
6. ImportMachine updates state, emits SaveResource command
7. DatabaseEffect executes: INSERT with PENDING status
8. Admin reviews in queue, clicks Approve (GraphQL mutation)
9. ApprovalMachine emits ApproveResource command
10. DatabaseEffect: UPDATE status='APPROVED' + audit log (atomic)
11. Public web queries GraphQL for approved resources

KEY BENEFITS OF THIS ARCHITECTURE:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Clear separation: GraphQL (external) vs seesaw-rs (internal coordination)
â€¢ Event-driven: Machines make pure decisions, effects do IO
â€¢ Transactional: One command = one atomic database operation
â€¢ Testable: Mock event bus and effects, test machines in isolation
â€¢ Auditable: All events are facts, replay for debugging
â€¢ Scalable: Add machines and effects independently
```

### Data Schema

#### ğŸš¨ CRITICAL SECURITY & DATA INTEGRITY FIXES REQUIRED

The schema below includes **critical fixes** discovered during research. The original schema had:
- **8 data integrity issues**: Missing cascade behaviors, no unique constraints, unsafe merge operations
- **5 security vulnerabilities**: Missing database-level access controls, no audit logging for deletes

**All fixes marked with ğŸ”§ MUST be applied before implementation.**

#### SQLx Migrations

**Create migrations directory**:
```bash
sqlx migrate add create_enums
sqlx migrate add create_resource_table
sqlx migrate add create_user_table
sqlx migrate add create_audit_log_table
sqlx migrate add create_matching_tables
sqlx migrate add create_indexes
```

**Migration 001: Create Extensions & Simple Status Types**
```sql
-- migrations/001_create_extensions.sql

-- Enable required PostgreSQL extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS vector;

-- Minimal status types (text-first, no rigid service taxonomy)
CREATE TYPE need_status AS ENUM (
    'active',      -- Currently seeking volunteers
    'filled',      -- No longer needs help
    'expired'      -- Time-bound need has passed
);
```

**Migration 002: Create Volunteers Table**
```sql
-- migrations/002_create_volunteers.sql

-- Volunteers: just text profiles (anti-fragile, evolvable)
CREATE TABLE volunteers (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name TEXT NOT NULL,
    email TEXT NOT NULL UNIQUE,
    phone TEXT,

    -- Just searchable text - no rigid structure
    -- This is the source of truth. AI can extract structure later if needed.
    searchable_text TEXT NOT NULL,

    -- Minimal metadata for operations
    embedding vector(1536),                    -- OpenAI text-embedding-3-small
    active BOOLEAN DEFAULT true,
    notification_count_this_week INTEGER DEFAULT 0,
    last_notified_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_volunteers_active ON volunteers(active) WHERE active = true;
CREATE INDEX idx_volunteers_email ON volunteers(email);
```

**Migration 003: Create Organization Needs Table**
```sql
-- migrations/003_create_needs.sql

-- Needs: just text descriptions (text-first storage)
CREATE TABLE organization_needs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    organization_name TEXT NOT NULL,

    -- Just searchable text - no rigid taxonomy
    -- AI-generated from scraped content, human-approved
    searchable_text TEXT NOT NULL,

    -- Minimal metadata (NOT for filtering, just for notification tone)
    source_url TEXT,
    urgency TEXT,  -- Just hints for notification phrasing ("urgent", "flexible", etc.)
    status TEXT DEFAULT 'active',  -- active, filled, expired

    -- Vector embedding
    embedding vector(1536),
    scraped_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE INDEX idx_needs_status ON organization_needs(status) WHERE status = 'active';
CREATE INDEX idx_needs_org ON organization_needs(organization_name);
```

**Migration 004: Create Notifications Table**
```sql
-- migrations/004_create_notifications.sql

-- Track who was notified (for learning, not enforcement)
-- This is NOT a "match" table - no lifecycle, no bilateral acknowledgment
CREATE TABLE notifications (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    need_id UUID REFERENCES organization_needs(id),
    volunteer_id UUID REFERENCES volunteers(id),

    -- What we told them (transparency)
    why_relevant TEXT,
    notified_at TIMESTAMPTZ DEFAULT NOW(),

    -- Did they engage? (optional - can add analytics later)
    clicked BOOLEAN DEFAULT false,
    responded BOOLEAN DEFAULT false
);

CREATE INDEX idx_notifications_need ON notifications(need_id);
CREATE INDEX idx_notifications_volunteer ON notifications(volunteer_id);
CREATE INDEX idx_notifications_notified_at ON notifications(notified_at DESC);
```

**Migration 005: Create Vector Indexes**
```sql
-- migrations/005_create_indexes.sql

-- Vector similarity indexes (IVFFLAT for simplicity, can upgrade to HNSW later)
CREATE INDEX idx_volunteers_embedding ON volunteers
    USING ivfflat (embedding vector_cosine_ops);

CREATE INDEX idx_needs_embedding ON organization_needs
    USING ivfflat (embedding vector_cosine_ops);

-- Note: RLS (Row-Level Security) is OPTIONAL for MVP
-- We're skipping it initially since GraphQL already mediates access
-- Can be enabled later when we have real users and real threat models
```

#### Rust Type Definitions

```rust
// crates/db/src/models/volunteer.rs

use chrono::{DateTime, Utc};
use pgvector::Vector;
use serde::{Deserialize, Serialize};
use uuid::Uuid;

#[derive(Debug, Clone, Serialize, Deserialize, sqlx::FromRow)]
pub struct Volunteer {
    pub id: Uuid,
    pub name: String,
    pub email: String,
    pub phone: Option<String>,

    // Just searchable text - no rigid structure
    pub searchable_text: String,

    // Minimal metadata for operations
    pub embedding: Option<Vector>,
    pub active: bool,
    pub notification_count_this_week: i32,
    pub last_notified_at: Option<DateTime<Utc>>,
    pub created_at: DateTime<Utc>,
}

// crates/db/src/models/need.rs

#[derive(Debug, Clone, Serialize, Deserialize, sqlx::FromRow)]
pub struct OrganizationNeed {
    pub id: Uuid,
    pub organization_name: String,

    // Just searchable text
    pub searchable_text: String,

    // Minimal metadata
    pub source_url: Option<String>,
    pub urgency: Option<String>, // Just for notification phrasing, not filtering
    pub status: String, // active, filled, expired
    pub embedding: Option<Vector>,
    pub scraped_at: DateTime<Utc>,
}

// crates/db/src/models/notification.rs

#[derive(Debug, Clone, Serialize, Deserialize, sqlx::FromRow)]
pub struct Notification {
    pub id: Uuid,
    pub need_id: Uuid,
    pub volunteer_id: Uuid,
    pub why_relevant: String,
    pub notified_at: DateTime<Utc>,
    pub clicked: bool,
    pub responded: bool,
}
```

### GraphQL Schema (Simplified for MVP)

**Single Endpoint**: `POST /graphql` (with GraphiQL at `GET /graphiql` for development)

**Philosophy**: We notify, we don't coordinate. No match lifecycle, no bilateral acknowledgment.

**Schema Definition**:
```graphql
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                      QUERIES (Read Operations)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type Query {
  # Public - active needs anyone can see
  needs(
    status: String = "active",
    limit: Int = 50,
    cursor: ID
  ): NeedConnection!

  need(id: ID!): OrganizationNeed

  # Admin only - CSV import management
  csvImports(limit: Int = 20): [CsvImport!]!

  # Public - volunteer's own notifications
  myNotifications(limit: Int = 20): [Notification!]!
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                     MUTATIONS (Write Operations)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type Mutation {
  # Volunteer registration (public, anonymous)
  registerVolunteer(input: RegisterVolunteerInput!): Volunteer!
  pauseNotifications(days: Int!): Volunteer!

  # Admin - CSV import (generic column mapper)
  importCsv(file: Upload!, columnMapping: JSON!): CsvImport!

  # Admin - need extraction from org websites
  extractNeedFromUrl(url: String!, orgName: String!): OrganizationNeed!
  approveNeed(needId: ID!, searchableText: String): OrganizationNeed!
  rejectNeed(needId: ID!, reason: String!): Boolean!

  # Admin - manual need creation
  createNeed(input: CreateNeedInput!): OrganizationNeed!
  updateNeed(needId: ID!, input: UpdateNeedInput!): OrganizationNeed!
  markNeedFilled(needId: ID!): OrganizationNeed!

  # Notification tracking (optional analytics)
  markNotificationClicked(notificationId: ID!): Boolean!
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                           TYPES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

type Volunteer {
  id: ID!
  name: String!
  email: String!
  phone: String
  searchableText: String!  # What they wrote
  active: Boolean!
  notificationCountThisWeek: Int!
  createdAt: DateTime!
}

type OrganizationNeed {
  id: ID!
  organizationName: String!
  searchableText: String!  # AI-generated from website scrape
  sourceUrl: String
  urgency: String          # Just text, not enforced enum
  status: String!          # active, filled, expired
  scrapedAt: DateTime!
}

type Notification {
  id: ID!
  need: OrganizationNeed!
  volunteer: Volunteer!
  whyRelevant: String!     # Transparency: why did we notify them?
  notifiedAt: DateTime!
  clicked: Boolean!
}

type CsvImport {
  id: ID!
  filename: String!
  rowCount: Int!
  importedCount: Int!
  status: String!          # pending, processing, completed, failed
  createdAt: DateTime!
}

type NeedConnection {
  nodes: [OrganizationNeed!]!
  pageInfo: PageInfo!
}

type PageInfo {
  hasNextPage: Boolean!
  endCursor: ID
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                           INPUTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

input RegisterVolunteerInput {
  name: String!
  email: String!
  phone: String
  searchableText: String!  # Free-form: "I'm a bilingual lawyer, weekends, Minneapolis"
}

input CreateNeedInput {
  organizationName: String!
  searchableText: String!
  sourceUrl: String
  urgency: String
}

input UpdateNeedInput {
  searchableText: String
  urgency: String
  status: String
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                           SCALARS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

scalar DateTime
scalar JSON
scalar Upload
```

**Key Simplifications vs. Original Schema:**
1. âŒ Removed `ServiceType` enum - text-first, no rigid taxonomy
2. âŒ Removed `Match` type with `similarityScore` and match lifecycle
3. âŒ Removed `acceptMatch`, `declineMatch`, `viewMatch` mutations
4. âŒ Removed `confidenceScore` - no fake precision
5. âœ… Added simple `Notification` type - just tracking who was notified
6. âœ… Kept `searchableText` as source of truth - anti-fragile storage
7. âœ… Urgency is just text, not enforced enum - can evolve naturally

**Authentication**:
- Handled by Clerk (separate from GraphQL)
- JWT token passed in `Authorization: Bearer <token>` header
- GraphQL context extracts user ID and role from token
- Juniper resolvers check permissions per field

## Implementation Phases

The implementation is divided into **two parallel tracks** that can be developed somewhat independently:
- **Track A**: Resource Directory (import, review, display orgs)
- **Track B**: Matching System (needs, offers, vector matching, notifications)

Start with foundation work that supports both, then build Track A (simpler) followed by Track B (more complex).

---

### Phase 1: Foundation (Week 1, Days 1-2)

**Goal**: Basic project setup, database, auth, vector support

#### Tasks:
- [ ] Initialize Next.js project with TypeScript
  ```bash
  npx create-next-app@latest mndigitalaid --typescript --tailwind --app
  cd mndigitalaid
  ```

- [ ] Set up Prisma with PostgreSQL + pgvector
  - Create `prisma/schema.prisma` with ALL models (Resource, OrganizationNeed, VolunteerOffer, Match, etc.)
  - Install pgvector extension on database:
    ```sql
    CREATE EXTENSION IF NOT EXISTS vector;
    ```
  - Run migrations: `npx prisma migrate dev`

- [ ] Set up Clerk authentication
  - Sign up at clerk.com (free tier: 10,000 MAU)
  - Install `@clerk/nextjs`
  - Configure magic link in Clerk dashboard
  - Add Clerk middleware to protect `/admin` and `/org` routes
  - Create user roles: `admin`, `reviewer`, `organization`, `volunteer`

- [ ] Set up environment variables
  ```env
  # Database
  DATABASE_URL=postgresql://user:pass@host:5432/dbname

  # Authentication
  CLERK_SECRET_KEY=sk_...
  NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY=pk_...

  # AI APIs
  ANTHROPIC_API_KEY=sk-ant-...
  OPENAI_API_KEY=sk-...  # For embeddings

  # Notifications
  RESEND_API_KEY=re_...
  TWILIO_ACCOUNT_SID=AC...
  TWILIO_AUTH_TOKEN=...
  TWILIO_PHONE_NUMBER=+1...
  ```

- [ ] Install key dependencies
  ```bash
  npm install @prisma/client @clerk/nextjs ai openai resend twilio xlsx
  npm install -D prisma
  ```

- [ ] Create basic layout and navigation
  - Public layout with header/footer
  - Admin layout with sidebar navigation
  - Organization dashboard layout
  - Mobile-responsive Tailwind components

**Deliverables**:
- Working Next.js app with database (including pgvector)
- Authentication flow functional
- Multi-role support (admin, org, volunteer)
- All database tables created
- Clean UI foundation

---

### Phase 2: TRACK A - Data Import Pipeline (Week 1, Days 3-4)

**Goal**: Parse XLSX and process with Claude

#### Tasks:
- [ ] Install xlsx parsing library
  ```bash
  npm install xlsx
  ```

- [ ] Create XLSX upload interface (`/admin/import`)
  - File upload component (drag & drop)
  - Show preview of columns/rows
  - Trigger import button

- [ ] Build data processor service (`lib/processor/`)
  - `parseXLSX(file)`: Extract rows into JSON
  - `processResource(row)`: Send to Claude for extraction
  - `saveToDatabase(resource)`: Create in DB with PENDING status

- [ ] Implement Claude extraction prompt
  ```typescript
  const prompt = `Extract organization information from this data:
  ${JSON.stringify(row)}

  Return JSON with fields:
  - organizationName (required)
  - serviceType (food|shelter|medical|supplies|transportation|legal|financial|education|other)
  - contactPhone OR contactEmail (at least one required)
  - address, city, state, zipCode
  - description, website
  - requirements

  Also provide:
  - confidenceScore (0-100): How confident are you this data is accurate?
  - suggestedDuplicates: Array of potential duplicate org names
  `;
  ```

- [ ] Add error handling with retry logic
  - Try 3x with exponential backoff (1s, 2s, 4s)
  - Log failures to database or file
  - Continue processing other rows on failure

- [ ] Create import status page
  - Show progress: "Processing row 45 of 200"
  - Display errors/warnings
  - Summary: "Imported 180, Failed 20"

**Deliverables**:
- XLSX upload working
- Claude extraction functional
- Resources in database with PENDING status
- Error logs for failed imports

---

### Phase 3: TRACK A - Review Queue (Week 1-2, Days 5-6)

**Goal**: Human verification interface

#### Tasks:
- [ ] Build queue list view (`/admin/queue`)
  - Fetch resources with status=PENDING
  - Sort by confidence (low confidence first)
  - Display: org name, type, contact, confidence score
  - Filters: by service type, by confidence range
  - Pagination (20 per page)

- [ ] Create resource review detail view (`/admin/queue/[id]`)
  - Display all fields in editable form
  - Show original source data (if available)
  - Highlight fields with low confidence
  - Show suggested duplicates section

- [ ] Implement review actions
  - **Approve**: Change status to APPROVED, set publishedAt
  - **Edit & Approve**: Update fields, then approve
  - **Reject**: Change status to REJECTED, require reason
  - **Merge**: Mark as duplicate, link to canonical resource (future enhancement)

- [ ] Add audit logging
  - Record every action in AuditLog table
  - Store before/after values for edits
  - Track who reviewed and when

- [ ] Create admin dashboard (`/admin`)
  - Stats: Total pending, approved today, rejected
  - Recent activity log
  - Quick actions: "Review next high-priority item"

**Deliverables**:
- Functional review queue interface
- Approve/reject/edit actions working
- Audit trail implemented
- Admin dashboard with stats

---

### Phase 4: TRACK A - Public Feed (Week 2, Days 7-8)

**Goal**: Public-facing organization directory

#### Tasks:
- [ ] Create public feed page (`/` or `/orgs`)
  - Fetch resources with status=APPROVED
  - Sort by publishedAt DESC (newest first)
  - Paginate (50 per page)
  - Mobile-first design with cards

- [ ] Design organization card component
  ```tsx
  <OrganizationCard>
    <ServiceTypeIcon type={org.serviceType} />
    <h3>{org.organizationName}</h3>
    <p className="text-sm text-gray-600">{org.city}</p>
    <p className="line-clamp-2">{org.description}</p>

    <div className="flex gap-2">
      {org.contactPhone && (
        <Button href={`tel:${org.contactPhone}`}>Call</Button>
      )}
      {org.contactEmail && (
        <Button href={`mailto:${org.contactEmail}`}>Email</Button>
      )}
      {org.website && (
        <Button href={org.website}>Website</Button>
      )}
    </div>

    <p className="text-xs text-gray-500">
      Last verified: {formatRelativeTime(org.lastVerifiedAt)}
    </p>
  </OrganizationCard>
  ```

- [ ] Create organization detail page (`/orgs/[id]`)
  - Full information display
  - All contact methods
  - Description and requirements
  - "Share" button

- [ ] Add meta tags for SEO
  - OpenGraph tags for social sharing
  - Proper page titles and descriptions
  - Structured data (Schema.org) for nonprofits

- [ ] Implement "Share" functionality
  - Web Share API for mobile
  - Fallback: Copy link to clipboard

**Deliverables**:
- Public organization directory displaying approved orgs
- Mobile-responsive design
- Organization detail pages
- Share functionality

**CHECKPOINT**: At this point, Track A (Resource Directory) is functional end-to-end. Can launch as MVP 1.0 or continue to Track B.

---

### Phase 5: Notification Engine (Week 2, Days 9-12)

**Goal**: Build the relevance notifier - the core product

**Philosophy**: We notify, we don't coordinate. No match table, no accept/decline, no similarity scores shown.

#### Tasks:

**Step 1: Volunteer Registration (Expo App)**
- [ ] Build volunteer registration form (Expo)
  - Name, email, phone (optional)
  - Large textarea: "What can you help with?"
  - Example: "I'm a bilingual lawyer with immigration experience. Available weekends. Based in Minneapolis."
  - Register push notification token (Expo)
  - NO auth required - just email for contact

- [ ] Implement registration mutation (GraphQL)
  ```graphql
  mutation RegisterVolunteer($input: RegisterVolunteerInput!) {
    registerVolunteer(input: $input) {
      id
      name
      email
    }
  }
  ```

- [ ] Create embedding for volunteer on registration (Rust)
  ```rust
  // crates/scraper/src/embeddings.rs
  pub async fn embed_volunteer(&self, volunteer: &Volunteer) -> Result<Vec<f32>> {
      let embedding = self.rig_client
          .embeddings("text-embedding-3-small")
          .embed_query(&volunteer.searchable_text)
          .await?;
      Ok(embedding)
  }
  ```

**Step 2: Need Extraction & Approval (Admin SPA)**
- [ ] Build CSV import with column mapper (Admin SPA)
  - Upload CSV â†’ preview columns â†’ map to org name, website, etc.
  - Store orgs (optional intermediate table) or go directly to needs

- [ ] Scrape org websites (Firecrawl via Rust)
  ```rust
  // crates/scraper/src/firecrawl.rs
  pub async fn scrape_url(&self, url: &str) -> Result<String> {
      // Call Firecrawl API
      // Return markdown content
  }
  ```

- [ ] Extract needs with rig.rs (GPT-4o)
  ```rust
  // crates/scraper/src/extractor.rs
  pub async fn extract_needs(
      &self,
      scraped_content: &str,
      org_name: &str,
  ) -> Result<Vec<ExtractedNeed>> {
      let prompt = format!(
          "Extract volunteer needs from this org's website:\n\n{}",
          scraped_content
      );
      // Returns: [{ searchable_text, urgency }]
  }
  ```

- [ ] **Admin approval with EDIT** (critical)
  - Admin sees suggested need with searchable_text
  - Admin can EDIT the text before approving (quality lever)
  - Admin clicks "Approve" â†’ need becomes active
  - Generate embedding for approved need

**Step 3: Notification Engine (Rust - Core Product)**
- [ ] Build relevance notifier (crates/matching)
  ```rust
  pub async fn process_need(&self, need_id: Uuid) -> Result<Vec<Uuid>> {
      // 1. Vector search: top 20 volunteers
      let candidates = self.find_candidates(&need, 20).await?;

      // 2. AI relevance check (generous)
      let evaluations = self.evaluate_relevance(&need, &candidates).await?;

      // 3. Filter to relevant only
      let relevant = evaluations.into_iter()
          .filter(|e| e.is_relevant)
          .collect();

      // 4. Apply throttle (max 3/week)
      let to_notify = self.apply_notification_limits(relevant, 5).await?;

      // 5. Send notifications
      for eval in &to_notify {
          self.send_notification(need_id, eval).await?;
      }

      Ok(to_notify.iter().map(|e| e.volunteer_id).collect())
  }
  ```

- [ ] Implement AI relevance judgment (rig.rs)
  ```rust
  async fn evaluate_relevance(
      &self,
      need: &OrganizationNeed,
      candidates: &[Volunteer],
  ) -> Result<Vec<RelevanceEvaluation>> {
      let prompt = format!(
          "For each person, decide if this opportunity is RELEVANT to them.
          Be generous - if there's a reasonable chance they'd want to know, mark it relevant.

          Opportunity: {}

          People: {}

          Return JSON: [{{ candidate_number, is_relevant, why }}]",
          need.searchable_text, format_candidates(candidates)
      );
      // Parse response, return evaluations
  }
  ```

- [ ] Send push notifications (Expo)
  ```rust
  async fn send_notification(
      &self,
      need_id: Uuid,
      eval: &RelevanceEvaluation,
  ) -> Result<()> {
      let volunteer = self.fetch_volunteer(eval.volunteer_id).await?;

      let message = format!(
          "Thought you might be interested:\n\n{}\n\n{}",
          need.searchable_text,
          eval.why
      );

      // Send via Expo push API
      expo::send_push_notification(
          &volunteer.push_token,
          "New opportunity",
          &message
      ).await?;

      // Store notification record
      self.store_notification(need_id, eval).await?;
  }
  ```

- [ ] Implement notification view (Expo App)
  - List of received notifications
  - Tap notification â†’ see need details + org contact
  - **No accept/decline** - just show contact info
  - Volunteer decides if they reach out

**Step 4: Simple Analytics (Optional)**
- [ ] Track notification clicks
  ```rust
  mutation MarkNotificationClicked($id: ID!) {
    markNotificationClicked(notificationId: $id)
  }
  ```

- [ ] Admin dashboard shows:
  - Needs processed
  - Volunteers registered
  - Notifications sent
  - Click rate (optional)

**What We're NOT Building:**
- âŒ Match table or match lifecycle
- âŒ Accept/decline match buttons
- âŒ Similarity scores shown to users
- âŒ Volunteer dashboards with "your matches"
- âŒ Org dashboards viewing volunteers
- âŒ Confidence scores or thresholds visible

**Deliverables**:
- Volunteers can register via Expo app
- Admins can extract and approve needs (with edit)
- Notification engine sends relevant opportunities
- Push notifications working
- Simple tracking (clicked/responded)

---

### Phase 6: Polish & Deploy (Week 3, Days 13-16)

**Goal**: Production-ready system on Fly.io

#### Tasks:
- [ ] Build Rust workspace structure
  - Initialize Cargo workspace with crates (api, core, db, matching, scraper)
  - Set up SQLx migrations
  - Configure Juniper GraphQL schema

- [ ] Build & embed admin SPA
  ```bash
  cd frontend/admin-spa
  npm run build  # Creates dist/

  # Rust embeds dist/ at compile time via rust-embed
  cargo build --release -p api
  ```

- [ ] Deploy to Fly.io
  ```bash
  flyctl launch
  flyctl postgres create --name mndigitalaid-db --region ord
  flyctl postgres attach mndigitalaid-db
  flyctl secrets set OPENAI_API_KEY=sk-...
  flyctl deploy
  ```

- [ ] Manual testing end-to-end
  - CSV import â†’ admin approves need â†’ volunteers notified
  - Volunteer taps notification â†’ sees contact â†’ reaches out
  - NO match accept/decline workflow

- [ ] Documentation
  - README with setup instructions
  - Admin guide (CSV import, approve needs)
  - Deployment guide (Fly.io commands)

**Deliverables**:
- Single Rust binary deployed to Fly.io
- Admin SPA embedded (served from Rust)
- Expo app deployed (EAS or Vercel web)
- System tested end-to-end
- Documentation complete

---

### Future Enhancements (Post-MVP)

**Not part of MVP:**

- [ ] Web scraping automation (scheduled Firecrawl runs)
- [ ] Stale need management (auto-expire after 30 days)
- [ ] Volunteer pause notifications (temporary opt-out)
- [ ] SMS notifications (Twilio integration)
- [ ] Multi-language support (Spanish, Somali, Hmong)
- [ ] Analytics dashboard (notification open rates, response rates)

**Things We're Deliberately NOT Building (Yet):**
- âŒ Match lifecycle (accept/decline/viewed)
- âŒ Similarity score thresholds or confidence scores (keep ephemeral)
- âŒ ServiceType enum (stay text-first)
- âŒ Org dashboards viewing volunteer profiles
- âŒ Volunteer dashboards with match management
- âŒ Bilateral acknowledgment workflows

**Why Not?** Because we don't know what matters yet. Let usage teach us.

---

## References & Research

### Internal References
- Original spec document from prior conversation (comprehensive architecture)
- XLSX data source: `/Users/crcn/Developer/fourthplaces/mndigitalaid/docs/Immigrant Resources for Action (January 2026) - Copy.xlsx`

### External References
- **Rust Documentation**: https://doc.rust-lang.org/
- **SQLx Documentation**: https://docs.rs/sqlx/
- **Juniper (GraphQL)**: https://docs.rs/juniper/
- **rig.rs (AI/LLM)**: https://docs.rig.rs/
- **Axum (HTTP Server)**: https://docs.rs/axum/
- **pgvector**: https://github.com/pgvector/pgvector
- **Fly.io Deployment**: https://fly.io/docs/
- **rust-embed**: https://docs.rs/rust-embed/
- **Clerk Authentication**: https://clerk.com/docs (admin only)
- **Expo**: https://docs.expo.dev/
- **Firecrawl API**: https://docs.firecrawl.dev/
- **xlsx Package**: https://www.npmjs.com/package/xlsx
- **Tailwind CSS**: https://tailwindcss.com/docs

### Best Practices
- **Accessibility**: WCAG 2.1 AA standards for public interfaces
- **Mobile-First Design**: 60%+ of emergency resource seekers use mobile devices
- **Error Recovery**: Always provide retry mechanisms for failed operations
- **Audit Trails**: Log all data modifications for accountability
- **Data Validation**: Validate at database, API, and UI levels

### Related Projects
- 211 helpline systems (telephone information and referral service)
- FindHelp.org (national resource directory)
- Local government emergency resource pages

---

## ğŸ”’ Data Integrity & Migration Safety

Research identified **8 critical data integrity issues**:

### 1. Missing Cascade Behaviors (CRITICAL)

**Problem**: Deleting a resource leaves orphaned audit logs. Deleting a user who reviewed resources causes foreign key constraint violation.

**Fix**: Already added to schema - all foreign keys now have appropriate cascade behaviors:
- `Resource` â†’ `AuditLog`: `onDelete: Cascade` (delete logs with resource)
- `User` â†’ `AuditLog`: `onDelete: Restrict` (prevent deleting users with audit history)
- `Resource` â†’ `OrganizationNeed`: `onDelete: SetNull` (unlink when resource deleted)

### 2. No Duplicate Prevention at Database Level

**Problem**: Unique constraint only on `[organizationName, city]` - can still create duplicates with slight name variations.

**Fix**: Implement safe merge operation:
```typescript
async function mergeResources(primaryId: string, duplicateId: string, userId: string) {
  return await prisma.$transaction(async (tx) => {
    // 1. Move all audit logs to primary resource
    await tx.auditLog.updateMany({
      where: { resourceId: duplicateId },
      data: { resourceId: primaryId }
    })

    // 2. Move all organization needs
    await tx.organizationNeed.updateMany({
      where: { organizationId: duplicateId },
      data: { organizationId: primaryId }
    })

    // 3. Create merge audit log
    await tx.auditLog.create({
      data: {
        resourceId: primaryId,
        userId,
        action: 'merged',
        changes: { mergedFrom: duplicateId },
        reason: 'Duplicate merged'
      }
    })

    // 4. Delete duplicate
    await tx.resource.delete({
      where: { id: duplicateId }
    })
  })
}
```

### 3. Stale Embedding Detection Missing

**Problem**: If embedding model changes (e.g., OpenAI updates `text-embedding-3-small`), old embeddings become incompatible with new ones, breaking matching.

**Fix**: Embedding version tracking (already added to schema):
```typescript
// When embedding model changes
async function migrateEmbeddings(newVersion: number) {
  // 1. Mark all embeddings as stale
  await prisma.organizationNeed.updateMany({
    data: { embeddingStale: true }
  })

  await prisma.volunteerOffer.updateMany({
    data: { embeddingStale: true }
  })

  // 2. Re-embed in batches
  const needs = await prisma.organizationNeed.findMany({
    where: { embeddingStale: true },
    select: { id: true, description: true }
  })

  for (const need of needs) {
    const embedding = await generateEmbedding(need.description)
    await prisma.organizationNeed.update({
      where: { id: need.id },
      data: {
        embedding,
        embeddingVersion: newVersion,
        embeddingStale: false
      }
    })
  }
}
```

### 4. No Rollback Plan for Migrations

**Problem**: Database migrations are one-way. If migration causes issues in production, no safe rollback.

**Fix**: Write rollback migrations:
```sql
-- migrations/YYYYMMDD_add_embedding_version_up.sql
ALTER TABLE "OrganizationNeed" ADD COLUMN "embeddingVersion" INTEGER DEFAULT 1;
ALTER TABLE "OrganizationNeed" ADD COLUMN "embeddingStale" BOOLEAN DEFAULT FALSE;

-- migrations/YYYYMMDD_add_embedding_version_down.sql
ALTER TABLE "OrganizationNeed" DROP COLUMN "embeddingVersion";
ALTER TABLE "OrganizationNeed" DROP COLUMN "embeddingStale";
```

Test rollback in staging:
```bash
# Apply migration
npx prisma migrate deploy

# Test in production for 24 hours

# If issues, rollback
psql $DATABASE_URL < migrations/YYYYMMDD_add_embedding_version_down.sql
```

### 5. Unsafe Merge Operations

**Problem**: Merging resources could lose data if not done in transaction.

**Fix**: See merge operation above - uses Prisma transaction for atomicity.

### 6. Missing NOT NULL Constraints

**Problem**: Critical fields like `serviceType`, `status` allow NULL in database (even though Prisma marks them required).

**Fix**: Add CHECK constraints in migration:
```sql
ALTER TABLE "Resource" ADD CONSTRAINT check_service_type
  CHECK (service_type IS NOT NULL);

ALTER TABLE "Resource" ADD CONSTRAINT check_status
  CHECK (status IS NOT NULL);
```

### 7. No Audit Logging for Deletes

**Problem**: When resource deleted, no record of who deleted it or why.

**Fix**: Soft delete pattern:
```typescript
// Instead of DELETE
await prisma.resource.delete({ where: { id } })

// Use soft delete
await prisma.resource.update({
  where: { id },
  data: {
    status: 'ARCHIVED',
    auditLogs: {
      create: {
        userId,
        action: 'deleted',
        reason: 'Spam / outdated / duplicate'
      }
    }
  }
})
```

### 8. Vector Embedding Race Conditions

**Problem**: Embedding generation is async. If offer submitted and matched before embedding completes, match fails.

**Fix**: Use database triggers or queue pattern:
```typescript
// Option 1: Wait for embedding before marking active
export async function createVolunteerOffer(data: OfferInput) {
  // 1. Create with PENDING status
  const offer = await prisma.volunteerOffer.create({
    data: {
      ...data,
      status: 'PENDING' // Not searchable yet
    }
  })

  // 2. Generate embedding
  const embedding = await generateEmbedding(data.description)

  // 3. Activate and trigger matching
  const activeOffer = await prisma.volunteerOffer.update({
    where: { id: offer.id },
    data: {
      embedding,
      embeddingVersion: CURRENT_EMBEDDING_VERSION,
      status: 'ACTIVE' // Now searchable
    }
  })

  // 4. Find matches asynchronously
  await findAndCreateMatches(activeOffer.id)

  return activeOffer
}
```

**Migration Safety Checklist:**

- [ ] Test all migrations in development first
- [ ] Test migrations on production snapshot (restore backup to staging)
- [ ] Write and test rollback migrations
- [ ] Back up production database before migration
- [ ] Run migration during low-traffic window
- [ ] Monitor database performance after migration (check slow queries)
- [ ] Have rollback plan ready (script + person on call)
- [ ] Verify data integrity after migration (count checks, sample queries)

## Getting Started

Once this plan is approved, execute phases in order:

1. **Phase 1**: Set up project foundation (Next.js, DB, auth)
2. **Phase 2**: Build import pipeline (parse XLSX, Claude extraction)
3. **Phase 3**: Create review queue (admin interface)
4. **Phase 4**: Launch public feed (public interface)
5. **Phase 5**: Polish and deploy to production

**Estimated Total Time**: 2-3 weeks for MVP
**Estimated Cost**: $50-100/month (Clerk free tier, Railway/Supabase free tier, Claude API ~$30-50)

**âš ï¸ CRITICAL: Before starting implementation, address the 23 security vulnerabilities, 7 performance bottlenecks, and 8 data integrity issues documented in this enhanced plan.**

This plan provides a clear path from empty repository to functioning emergency resource aggregator that helps people in crisis find the help they need.
